{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Competition 1: Personality Profiling of YouTube vloggers (round 2 ) #\n\n*Team 15: Lisa, Bart, & Julius*\n\n\nThis notebook tests different models that predict vloggers personality (Big Five) based on their video transcripts, audiovisual features, and gender. The Big Five personality traits are openness to experience, conscientiousness, extroversion, agreeableness, and emotional stability. We proceed in several steps:\n\n1. Import and format the input data\n2. Extract relevant features from the transcripts\n3. Formulate and compare different models\n4. Select the best model\n5. Predict unknown personality scores ","metadata":{}},{"cell_type":"markdown","source":"Before we start, we load the tidyverse and tidytext packages necessary to run our code.","metadata":{}},{"cell_type":"code","source":"library(tidyverse)\nlibrary(tidytext)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:46.168551Z","iopub.execute_input":"2023-09-18T09:41:46.171311Z","iopub.status.idle":"2023-09-18T09:41:46.195293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Import and format input data ##\n\n\nFirst, we identifiy the file paths of our transcripts, audiovisual, gender, and personality data.","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Collecting all pieces of the full dataset","metadata":{}},{"cell_type":"code","source":"youtube_dir <- file.path(list.files(\"../input\", full.names = TRUE), \"youtube-personality\") # file path to Youtube Personality directory\ndirectory_content <- list.files(youtube_dir, full.names = TRUE) # contents of Youtube Personality directory\nprint(directory_content)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:46.199857Z","iopub.execute_input":"2023-09-18T09:41:46.20244Z","iopub.status.idle":"2023-09-18T09:41:46.236853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For each file, we save the corresponding file path.","metadata":{}},{"cell_type":"code","source":"path_to_transcripts <- directory_content[2] # path to directory with transcript\nAudioVisual_file    <- directory_content[3] # path to .csv file with audiovisual data\nGender_file         <- directory_content[4] # path to .csv file with gender data\nPersonality_file    <- directory_content[5] # path to .csv file with personality data","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:46.241304Z","iopub.execute_input":"2023-09-18T09:41:46.243838Z","iopub.status.idle":"2023-09-18T09:41:46.274741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"While the audiovisual, gender, and personality data are stored in files containing data for all vloggers (except missing values), the transcripts are stored individually for each vlogger in the transcripts directory.","metadata":{}},{"cell_type":"code","source":"transcript_files <- list.files(path_to_transcripts, full.names = TRUE) # contents of transcripts directory\nprint(head(transcript_files))","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:46.279203Z","iopub.execute_input":"2023-09-18T09:41:46.281655Z","iopub.status.idle":"2023-09-18T09:41:46.317058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The file name for each vlogger's transcript contains the vlogger ID, which we extract to later use as identifiers in our data frames.","metadata":{}},{"cell_type":"code","source":"vlogId <- basename(transcript_files) # extracting file names\nvlogId <- str_replace(vlogId, pattern = \".txt$\", replacement = \"\") # remove .txt\nhead(vlogId)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:46.321942Z","iopub.execute_input":"2023-09-18T09:41:46.324846Z","iopub.status.idle":"2023-09-18T09:41:46.360664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we combine all transcripts in a data frame with three columns, The first column contains the vlogger IDs, the second column contains the text of the corresponding transcripts, and the third column contains the file names.","metadata":{}},{"cell_type":"code","source":"transcripts_df <- tibble(\n    vlogId = vlogId, # vlogger IDs\n    TEXT = map_chr(transcript_files, ~ paste(readLines(.x), collapse = \"\\\\n\")), # transcripts as string\n    filename = transcript_files # name of source file\n)\nhead(transcripts_df, 2)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:46.365214Z","iopub.execute_input":"2023-09-18T09:41:46.367843Z","iopub.status.idle":"2023-09-18T09:41:46.976404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.2 Creating the full dataset ","metadata":{}},{"cell_type":"markdown","source":"The personality, audiovisual, and gender files already contain the vlogger IDs and corresponding data. The column with the vlogger IDs is called 'vlogId' in the personality and audiovisual data but has no name in the gender data, so we need to add it before we can join them into a combined data frame by the vlogger IDs. We use a left-join to make sure that we keep the data of all vloggers for whom we have scores on the outcome variables (i.e. personality traits). This results in one data frame 'vlogger_df' with personality, audiovisual, and gender data for each vlogger.\n\nWe decided to add the audiovisual data because when comparing the same linear model with and without the audiovisual data, the model with audiovisual data scored higher on the adjusted R^2 for all of the five personality aspects (shown later in the notebook). To check this, we also made a dataset without audiovisual features","metadata":{}},{"cell_type":"code","source":"pers_df          <- read_delim(Personality_file, delim = \" \") # import personality scores\naudio_vis_df     <- read.delim(AudioVisual_file, head = TRUE, sep = \" \") # import audiovisual data\ngender_df        <- read.delim(Gender_file, head = FALSE, sep = \" \", skip = 1) # import gender data\nnames(gender_df) <- c(\"vlogId\", \"gender\") # add column names to gender data\n\n# dataset without audiovisual features\nvlogger_df_no_audiovis <- list(gender_df, pers_df) %>%\n                            reduce(left_join, by = \"vlogId\")\n\n# the full dataset\nvlogger_df       <- list(gender_df, pers_df, audio_vis_df) %>%\n                        reduce(left_join, by = \"vlogId\")\nhead(vlogger_df)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:46.979243Z","iopub.execute_input":"2023-09-18T09:41:46.981057Z","iopub.status.idle":"2023-09-18T09:41:47.388515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Extract relevant features from the transcripts ##","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Trying out the SMART stopwords","metadata":{}},{"cell_type":"markdown","source":"Before we can scan the transcripts for relevant features, we need to split them into tokens in a new 'transcripts_tokenized' data frame. Tokens can be categorised using different lexicons. We decided to use words as out tokens and as a step of pre-processing the tokenized transcripts we exclude so-called stopwords, which carry little meaning by themselves. We were deciding between the 'SMART' stopword list from the tm package and the 'snowball' list of stopwords from tidytext package, because the later is a bit focused on certain things e.g. exaggerations, which might carry meaning in the word lists. In the end we agreed on using the stopwords from the 'snowball' list, because it consists only of 175 words (vs. 571 words from 'SMART') and therefore remove less words from our tokenized words, which potentially carry meaning and leads to a better prediction model. On top of that, after importing the lexicons in a later step, we also checked for any accidental removal of imporant words by looking at the overlap between stopwords and the ocean words list, with which we were fine. Apart from this we thought about identifying near zero variance of the tokenized transcript as well as checking for highly correlated variables and highly correlated linear combinations, in order to improve the model performance. It turned out this is not really applicable to the tokenized transcripts, which are encoded as characters. To finish off our pre-processing we wanted to have all tokenized words in lowercase to have a coherent representation of words. ","metadata":{}},{"cell_type":"code","source":"# Helper function to retrieve different lexicons from the 'textdata' package\nget_lexicon <- function(lexicon_name = names(textdata:::download_functions)) {\n    lexicon_name = match.arg(lexicon_name)\n    textdata:::download_functions[[lexicon_name]](\".\")\n    rds_filename = paste0(lexicon_name,\".rds\")\n    textdata:::process_functions[[lexicon_name]](\".\",rds_filename)\n    readr::read_rds(rds_filename)\n}","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:47.391868Z","iopub.execute_input":"2023-09-18T09:41:47.394035Z","iopub.status.idle":"2023-09-18T09:41:47.413387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Trying out different stopword list called SMART\n# Load SMART stopwords from the tm package\nlibrary(tm)\nlibrary(NLP)\n\n# Access SMART stopwords\nstopwords <- stopwords(\"SMART\") \n\n# the SMART stopwords are less focused on exaggerations, but still have personal pronounce in there\n# but consists of more words 571 vs. 175 from snowball\nstopwords <- as.data.frame(stopwords, col.names = \"word\")\ncolnames(stopwords) <- c(\"word\")\n\ntranscripts_tokenized2 <- transcripts_df %>%\n    unnest_tokens(word, TEXT, token = \"words\") %>% # split text into words\n    anti_join(stopwords, by = \"word\") # remove stopwords\n\n# remove stopwords\ntranscripts_tokenized2 <- transcripts_tokenized2 %>%\n    anti_join(stopwords, by = \"word\") \n\n# count tokens (sort according to number of occurences)\nfrequencies <- transcripts_tokenized2 %>%\n    count(word, sort=TRUE)\n\n# load NRC word list\nnrc <- get_lexicon('nrc')\n\n# Do an left join an essay token data fame and nrc word list\ntranscript_features_df2 <- left_join(transcripts_tokenized2, nrc, by = \"word\", relationship = \"many-to-many\")\ntranscript_features_df2 <- transcript_features_df2[,-2]\n\n# Calculate sentiment scores\ntranscript_features_df2 <- transcript_features_df2 %>%\n    count(`vlogId`, sentiment)\n\ntranscript_features_df2 <- transcript_features_df2 %>% pivot_wider(id_cols = \"vlogId\", names_from = sentiment,\n                                                                values_from = n, values_fill = 0)\n\nvlogger_df_smart <- right_join(pers_df, transcript_features_df2, by = \"vlogId\")\n\n# Only for demonstration purposes:\nfit_SMART <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ ., data = vlogger_df[,-1])\nsummary(fit_SMART)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-18T09:41:47.418113Z","iopub.execute_input":"2023-09-18T09:41:47.420543Z","iopub.status.idle":"2023-09-18T09:41:52.46632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 Choosing the snowball stopwords","metadata":{}},{"cell_type":"code","source":"stopwords <- get_stopwords() # 'snowball' list of stopwords from tidytext package \n\ntranscripts_tokenized <- transcripts_df %>%\n    unnest_tokens(word, TEXT, token = \"words\") %>% # split text into words\n    anti_join(stopwords, by = \"word\") # remove stopwords\n\nhead(transcripts_tokenized)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:52.471134Z","iopub.execute_input":"2023-09-18T09:41:52.473778Z","iopub.status.idle":"2023-09-18T09:41:52.727195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3 Choosing lexicons","metadata":{}},{"cell_type":"markdown","source":"To interpret the words as part of our models, we categorise them using two alternative lexicons. The NRC lexicon from the tidytext package attaches a sentiment to a large number of words. We load the NRC lexicon using the 'get_lexicon' helper function. The OCEAN Words lexicon attaches a personality trait to different words. The OCEAN Words data was taken from the supplementary materials of Kern et al. (2014), who established the association between these words and the Big Fiver personality traits in their study.\n\nWe create a new data frame with one row per word and vlogger (from the 'transcripts_tokenized' data frame) and the category corresponding to each word according to lexicons using a left-join.\n\nWe tried models with only the nrc sentiments added, only the ocean word sentiments, and both added to see whether the adjusted R^2 would increase when we the words in the transcripts would have multiple sentiment categories.","metadata":{}},{"cell_type":"code","source":"# Add category of each word according to NRC (sentiment) and OCEAN Words (personality)\nnrc_df                 <- get_lexicon(\"nrc\")\nocean_df               <- read_csv(\"../input/ocean-words/OCEAN_words.csv\")\n\n# clean column names\nnames(ocean_df)        <- c(\"highExtraversion\", \"lowExtraversion\", \"highAgreeableness\", \"lowAgreeableness\",\n                            \"lowConscientiousness\", \"highConscientiousness\", \"highES\",\n                            \"lowES\", \"highOpenness\", \"lowOpenness\") \n\n# pivot to two columns with words and personality traits\nocean_df               <- ocean_df %>% pivot_longer(cols = everything(),\n                                                    names_to = \"trait\",\n                                                    values_to = \"word\") \n\n# check for an accidental removal of imporant words by the stopword list\noverlap_words1         <- semi_join(stopwords, ocean_df, by = \"word\") \noverlap_words2         <- semi_join(stopwords, nrc_df, by = \"word\") \n\n# dataframe with only the nrc word categories added\ntranscript_nrc <- list(transcripts_tokenized, nrc_df) %>%\n                    reduce(left_join, by = \"word\", relationship = \"many-to-many\")\n\n# dataframe with only the ocean word categories added\ntranscript_ocean <- list(transcripts_tokenized, ocean_df) %>%\n                    reduce(left_join, by = \"word\", relationship = \"many-to-many\")\n\n# dataframe with both word categories added\ntranscript_features_df <- list(transcripts_tokenized, nrc_df, ocean_df) %>%\n                            reduce(left_join, by = \"word\", relationship = \"many-to-many\")\n\nhead(transcript_features_df, 20)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:52.730191Z","iopub.execute_input":"2023-09-18T09:41:52.731596Z","iopub.status.idle":"2023-09-18T09:41:53.109983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We turn our tokens into quantitative pedictors by counting how many words of each sentiment and trait appear in each vlogger's transcript. We pivot the resulting date frames into a wide format and join them into a new data frame 'transcript_features_df'. ","metadata":{}},{"cell_type":"code","source":"# Calculate sentiment scores\nsentiment_features_df <- \n    transcript_features_df %>%\n    count(`vlogId`, sentiment) %>%\n    pivot_wider(id_cols = \"vlogId\", names_from = sentiment, values_from = n, values_fill = 0)\n\n# Calculate trait scores\ntrait_features_df <- \n    transcript_features_df %>%\n    count(`vlogId`, trait) %>%\n    pivot_wider(id_cols = \"vlogId\", names_from = trait, values_from = n, values_fill = 0)\n\ntranscript_features_df <- left_join(sentiment_features_df, trait_features_df, by = \"vlogId\")\n\nhead(transcript_features_df)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:53.113931Z","iopub.execute_input":"2023-09-18T09:41:53.115902Z","iopub.status.idle":"2023-09-18T09:41:53.322901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also tried to merge the high and low scores of each trait together with the code underneath. But this resulted in lower adjusted R-squared scores. It looks like the model uses combinations of high and low scores of certain traits to explain more variance.\n","metadata":{}},{"cell_type":"code","source":"tested_but_removed <- left_join(sentiment_features_df, trait_features_df, by = \"vlogId\") %>%\n                            mutate(\"Other\" = NA.x + NA.y, .keep = \"unused\") %>%\n                            mutate(\"Openness\" = highOpenness - lowOpenness, .keep = \"unused\") %>%\n                            mutate(\"Conscientiousness\" = highConscientiousness - lowConscientiousness, .keep = \"unused\") %>%\n                            mutate(\"Extraversion\" = highExtraversion - lowExtraversion, .keep = \"unused\") %>%\n                            mutate(\"Agreeableness\" = highAgreeableness - lowAgreeableness, .keep = \"unused\") %>%\n                            mutate(\"emotionalStability\" = highES - lowES, .keep = \"unused\")","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:53.325963Z","iopub.execute_input":"2023-09-18T09:41:53.327506Z","iopub.status.idle":"2023-09-18T09:41:53.352767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.4 Creating different dataframes","metadata":{}},{"cell_type":"markdown","source":"Finally, we merge the new 'transcript_features_df' with the audiovisual, gender, and personality data from the 'vlogger_df'. We now have a data frame with one row per vlogger and their associated personality, audiovisual, gender, and quantified transcript data. We also keep the four intermediate dataframes with only nrc sentiments and ocean sentiments, but also combined with the dataframe without audiovisual features and with audiovisual features. This results in 5 different dataframes to test our different models on!","metadata":{}},{"cell_type":"code","source":"# dataframe with nrc sentiments and no audiovisual features\nvlogger_df_basic_nrc <- right_join(vlogger_df_no_audiovis, sentiment_features_df, by = \"vlogId\")\n\n# dataframe with ocean sentiments and no audiovisual features\nvlogger_df_basic_ocean <- right_join(vlogger_df_no_audiovis, trait_features_df, by = \"vlogId\")\n\n# dataframe with nrc sentiments and audiovisual features\nvlogger_df_full_nrc <- right_join(vlogger_df, sentiment_features_df, by = \"vlogId\")\n\n# dataframe with ocean sentiments and audiovisual features\nvlogger_df_full_ocean <- right_join(vlogger_df, trait_features_df, by = \"vlogId\")\n\n# dataframe with both sentiments and audiovisual features\nvlogger_df_full_both <- right_join(vlogger_df, transcript_features_df, by = \"vlogId\")\n\nvlogger_df_full_both %>% head()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:53.355793Z","iopub.execute_input":"2023-09-18T09:41:53.357272Z","iopub.status.idle":"2023-09-18T09:41:53.436435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Formulate and compare different models ##","metadata":{}},{"cell_type":"markdown","source":"The following steps include running different multiple linear models, which differ in their degree of flexibility. This ranges from a full linear model with all available predictors to more sparse ones, where we identified the best predictors via a forward, backward and mix selection procedure.","metadata":{}},{"cell_type":"markdown","source":"### Model 1: The basics\nThe first model we tried just included the basics, so the sentiments from the nrc word list as predictors, no audiovisual features, and no interaction effects","metadata":{}},{"cell_type":"code","source":"model1 <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ ., data = vlogger_df_basic_nrc[,-1])\nsummary(model1)","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-09-18T09:41:53.439216Z","iopub.execute_input":"2023-09-18T09:41:53.440739Z","iopub.status.idle":"2023-09-18T09:41:53.47873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**This first model has adjusted R-squareds scores of [-0.003, 0.259, 0.098, 0.0956, 0] for Extraversion, Agreeableness, Conscientiousness, Emotional availability and Openness respectively.**","metadata":{}},{"cell_type":"markdown","source":"### Model 2: Basics with OCEAN word list","metadata":{}},{"cell_type":"markdown","source":"Our second model tried to use the different word list for sentiment attribution","metadata":{}},{"cell_type":"code","source":"model2 <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ ., data = vlogger_df_basic_ocean[,-1])\nsummary(model2)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:53.481418Z","iopub.execute_input":"2023-09-18T09:41:53.482933Z","iopub.status.idle":"2023-09-18T09:41:53.521676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The second model improves on the first model with the following adjusted R-squared scores [0.093, 0.252, 0.041, 0.079, 0.056] for Extraversion, Agreeableness, Conscientiousness, Emotional availability and Openness respectively.**","metadata":{}},{"cell_type":"markdown","source":"### Model 3: NRC with audiovisuals","metadata":{}},{"cell_type":"markdown","source":"Our third model uses the NRC sentiments with audiovisual features added","metadata":{}},{"cell_type":"code","source":"model3 <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ ., data = vlogger_df_full_nrc[,-1])\nsummary(model3)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:53.534365Z","iopub.execute_input":"2023-09-18T09:41:53.535966Z","iopub.status.idle":"2023-09-18T09:41:53.607394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The third model improves greatly on the first two models with adjusted R-squared scores of [0.309, 0.240, 0.172, 0.111, 0.093] for Extraversion, Agreeableness, Conscientiousness, Emotional availability and Openness respectively.**","metadata":{}},{"cell_type":"markdown","source":"### Model 4: OCEAN words with audiovisual features","metadata":{}},{"cell_type":"markdown","source":"Our 4th model uses the OCEAN word sentiments with added audiovisual features","metadata":{}},{"cell_type":"code","source":"model4 <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ ., data = vlogger_df_full_ocean[,-1])\nsummary(model4)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:53.611969Z","iopub.execute_input":"2023-09-18T09:41:53.614488Z","iopub.status.idle":"2023-09-18T09:41:53.691446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The fourth model improves slighty on the third model with adjusted R-squared scores of [0.340, 0.240, 0.127, 0.103, 0.131] for Extraversion, Agreeableness, Conscientiousness, Emotional availability and Openness respectively.**","metadata":{}},{"cell_type":"markdown","source":"### Model 5: Full model","metadata":{}},{"cell_type":"markdown","source":"Model 5 uses both NRC and OCEAN word lists and audiovisual features","metadata":{}},{"cell_type":"code","source":"model5 <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ ., data = vlogger_df_full_both[,-1])\nsummary(model5) ","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:53.69605Z","iopub.execute_input":"2023-09-18T09:41:53.698532Z","iopub.status.idle":"2023-09-18T09:41:53.786343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The fifth model improves slighty on the fourth model with adjusted R-squared scores of [0.331, 0.271, 0.164, 0.117, 0.142] for Extraversion, Agreeableness, Conscientiousness, Emotional availability and Openness respectively.**","metadata":{}},{"cell_type":"markdown","source":"### 6: Interaction model","metadata":{}},{"cell_type":"markdown","source":"To identifiy some likely interactions, we look at the correlations between our predictors and arrange them by magnitude. We include the two-way interactions between the most highly correlated audiovisual features in our preliminary model: sd.pitch*mean.conf.pitch, mean.spec.entropy*mean.pitch, mean.val.apeak*mean.conf.pitch, avg.voiced.seg*mean.spec.entropy, and sd.loc.apeak*mean.spec.entropy.","metadata":{}},{"cell_type":"code","source":"# Create correlation matrix of predictors\nvloggers_cor <- cor(vlogger_df_full_both[,8:54])\ndiag(vloggers_cor) <- NA # exclude correlations of variables with themsevels\n\n# Find hightest correlations\nvloggers_cor <- vloggers_cor %>%\n  as.data.frame() %>%\n  arrange(desc(abs(.))) %>%\n  head(5)\n\nvloggers_cor","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:53.791239Z","iopub.execute_input":"2023-09-18T09:41:53.793996Z","iopub.status.idle":"2023-09-18T09:41:53.881347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model6 <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ . + sd.pitch*mean.conf.pitch + mean.spec.entropy*mean.pitch +\n    mean.val.apeak*mean.conf.pitch + avg.voiced.seg*mean.spec.entropy + sd.loc.apeak*mean.spec.entropy,\n    data = vlogger_df_full_both[,-1])\n\nsummary(model6)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:53.883987Z","iopub.execute_input":"2023-09-18T09:41:53.885456Z","iopub.status.idle":"2023-09-18T09:41:53.960737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The sixth model is worse than the fifth model with adjusted R-squared scores of [0.331, 0.272, 0.153, 0.107, 0.135] for Extraversion, Agreeableness, Conscientiousness, Emotional availability and Openness respectively.**","metadata":{}},{"cell_type":"markdown","source":"## 4. Intermediate conclusion","metadata":{}},{"cell_type":"markdown","source":"So from the 6 models we tested above, the fifth model (with both word lists and audiovisual features) had the best adjusted R-squared scores. This is to be expected since we did add more predictors. To subsequently try and reduce chance of overfitting, we used stepwise regression to remove predictors that were not useful in the models","metadata":{}},{"cell_type":"markdown","source":"## 5. Stepwise regression","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Seperating the Big5","metadata":{}},{"cell_type":"markdown","source":"We can now use this final model to perform stepwise regression. This removes the predictors which are not adding significant value to the regression. This might help us to prevent adding noise to our model. \n\nTo actually perform this, we had to split up the model into each separate component for the stepAIC to work. We then looked at the common predictors that remained for the different components of the Big 5.","metadata":{}},{"cell_type":"code","source":"model5_1 <- lm(Extr ~ gender + mean.pitch + sd.pitch + mean.conf.pitch + \n    sd.conf.pitch + mean.spec.entropy + sd.spec.entropy + mean.val.apeak + \n    sd.val.apeak + mean.loc.apeak + sd.loc.apeak + mean.num.apeak + \n    sd.num.apeak + mean.energy + sd.energy + mean.d.energy + \n    sd.d.energy + avg.voiced.seg + avg.len.seg + time.speaking + \n    voice.rate + num.turns + hogv.entropy + hogv.median + hogv.cogR + \n    hogv.cogC + anger + anticipation + disgust + fear + joy + \n    negative + positive + sadness + surprise + trust + NA.x + \n    highConscientiousness + highExtraversion + highOpenness + \n    lowAgreeableness + lowConscientiousness + lowES + lowExtraversion + \n    NA.y + highES + lowOpenness + highAgreeableness, data = vlogger_df_full_both[,-1])\n\n\nMASS::stepAIC(model5_1, direction = \"backward\", trace = FALSE)\n\nmodel5_2 <- lm(Agr ~ gender + mean.pitch + sd.pitch + mean.conf.pitch + \n    sd.conf.pitch + mean.spec.entropy + sd.spec.entropy + mean.val.apeak + \n    sd.val.apeak + mean.loc.apeak + sd.loc.apeak + mean.num.apeak + \n    sd.num.apeak + mean.energy + sd.energy + mean.d.energy + \n    sd.d.energy + avg.voiced.seg + avg.len.seg + time.speaking + \n    voice.rate + num.turns + hogv.entropy + hogv.median + hogv.cogR + \n    hogv.cogC + anger + anticipation + disgust + fear + joy + \n    negative + positive + sadness + surprise + trust + NA.x + \n    highConscientiousness + highExtraversion + highOpenness + \n    lowAgreeableness + lowConscientiousness + lowES + lowExtraversion + \n    NA.y + highES + lowOpenness + highAgreeableness, data = vlogger_df_full_both[,-1])\n\nMASS::stepAIC(model5_2, direction = \"backward\", trace = FALSE)\n\nmodel5_3 <- lm(Cons ~ gender + mean.pitch + sd.pitch + mean.conf.pitch + \n    sd.conf.pitch + mean.spec.entropy + sd.spec.entropy + mean.val.apeak + \n    sd.val.apeak + mean.loc.apeak + sd.loc.apeak + mean.num.apeak + \n    sd.num.apeak + mean.energy + sd.energy + mean.d.energy + \n    sd.d.energy + avg.voiced.seg + avg.len.seg + time.speaking + \n    voice.rate + num.turns + hogv.entropy + hogv.median + hogv.cogR + \n    hogv.cogC + anger + anticipation + disgust + fear + joy + \n    negative + positive + sadness + surprise + trust + NA.x + \n    highConscientiousness + highExtraversion + highOpenness + \n    lowAgreeableness + lowConscientiousness + lowES + lowExtraversion + \n    NA.y + highES + lowOpenness + highAgreeableness, data = vlogger_df_full_both[,-1])\n\nMASS::stepAIC(model5_3, direction = \"backward\", trace = FALSE)\n\nmodel5_4 <- lm(Emot ~ gender + mean.pitch + sd.pitch + mean.conf.pitch + \n    sd.conf.pitch + mean.spec.entropy + sd.spec.entropy + mean.val.apeak + \n    sd.val.apeak + mean.loc.apeak + sd.loc.apeak + mean.num.apeak + \n    sd.num.apeak + mean.energy + sd.energy + mean.d.energy + \n    sd.d.energy + avg.voiced.seg + avg.len.seg + time.speaking + \n    voice.rate + num.turns + hogv.entropy + hogv.median + hogv.cogR + \n    hogv.cogC + anger + anticipation + disgust + fear + joy + \n    negative + positive + sadness + surprise + trust + NA.x + \n    highConscientiousness + highExtraversion + highOpenness + \n    lowAgreeableness + lowConscientiousness + lowES + lowExtraversion + \n    NA.y + highES + lowOpenness + highAgreeableness, data = vlogger_df_full_both[,-1])\n\nMASS::stepAIC(model5_4, direction = \"backward\", trace = FALSE)\n\nmodel5_5 <- lm(Open ~ gender + mean.pitch + sd.pitch + mean.conf.pitch + \n    sd.conf.pitch + mean.spec.entropy + sd.spec.entropy + mean.val.apeak + \n    sd.val.apeak + mean.loc.apeak + sd.loc.apeak + mean.num.apeak + \n    sd.num.apeak + mean.energy + sd.energy + mean.d.energy + \n    sd.d.energy + avg.voiced.seg + avg.len.seg + time.speaking + \n    voice.rate + num.turns + hogv.entropy + hogv.median + hogv.cogR + \n    hogv.cogC + anger + anticipation + disgust + fear + joy + \n    negative + positive + sadness + surprise + trust + NA.x + \n    highConscientiousness + highExtraversion + highOpenness + \n    lowAgreeableness + lowConscientiousness + lowES + lowExtraversion + \n    NA.y + highES + lowOpenness + highAgreeableness, data = vlogger_df_full_both[,-1])\n\nMASS::stepAIC(model5_5, direction = \"backward\", trace = FALSE)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:53.965787Z","iopub.execute_input":"2023-09-18T09:41:53.968568Z","iopub.status.idle":"2023-09-18T09:41:58.263323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We then took these and see what predictors we could remove:\n\nThe predictors that were dropped by the stepwise regression were: \n\n\n**mean.conf.pitch,\nsd.conf.pitch,\nsd.energy,\nanticipation,\nnegative,\nsadness,\nsurprise,\nhighConscientiousness,\nhighOpenness,\nlowES,\nhighAgreeableness**\n\nThe model without these predictors looks as follows:","metadata":{}},{"cell_type":"markdown","source":"### 5.2 Model with less predictors","metadata":{}},{"cell_type":"code","source":"model_stepped <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ gender + mean.pitch + sd.pitch + \n    mean.spec.entropy + sd.spec.entropy + mean.val.apeak + \n    sd.val.apeak + mean.loc.apeak + sd.loc.apeak + mean.num.apeak + \n    sd.num.apeak + mean.energy + mean.d.energy + \n    sd.d.energy + avg.voiced.seg + avg.len.seg + time.speaking + \n    voice.rate + num.turns + hogv.entropy + hogv.median + hogv.cogR + \n    hogv.cogC + anger + disgust + fear + joy + \n    positive + trust + NA.x + \n    highExtraversion +\n    lowAgreeableness + lowConscientiousness + lowExtraversion + \n    NA.y + highES + lowOpenness, data = vlogger_df_full_both[,-1])\n\nsummary(model_stepped)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:58.267064Z","iopub.execute_input":"2023-09-18T09:41:58.269177Z","iopub.status.idle":"2023-09-18T09:41:58.339931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****This stepwised model improves slighty on the fifth model with adjusted R-squared scores of [0.342, 0.285, 0.184, 0.137, 0.162] for Extraversion, Agreeableness, Conscientiousness, Emotional availability and Openness respectively.****","metadata":{}},{"cell_type":"markdown","source":"### 5.3 Visualization for model selection","metadata":{}},{"cell_type":"markdown","source":"In order to compare the different models, we used the adjusted R squared on the one hand for assessing the goodness of model fit and the RMSE on the other as a measure of prediction accuracy. We have decided on the adjusted R squared instead of the 'normal' R squared, because besides measuring the overall fit, it also punishes for the amount of predictors in the model.","metadata":{}},{"cell_type":"code","source":"# Visualisation of adjusted R squared\n\nmetrics = data.frame(\n  model = c(\"model1\", \"model1\", \"model1\", \"model1\", \"model1\", \"model2\", \"model2\",\n            \"model2\", \"model2\", \"model2\", \"model3\", \"model3\", \"model3\", \"model3\",\n            \"model3\", \"model4\", \"model4\", \"model4\", \"model4\", \"model4\", \"model5\",\n            \"model5\",\"model5\",\"model5\",\"model5\", \"stepwise model\", \"stepwise model\",\n            \"stepwise model\" , \"stepwise model\" , \"stepwise model\"),\n  trait = c(\"Extraversion\",\"Agreeableness\", \"Conscientiousness\", \"Emotional availability\", \"Openness\"),\n  adj._r_squared = c(-0.003, 0.259, 0.098, 0.0956, 0.000, 0.093, 0.252,\n                     0.041, 0.079, 0.056, 0.309, 0.240, 0.172, 0.111, 0.093,\n                     0.340, 0.240, 0.127, 0.103, 0.131, 0.331, 0.271, 0.164,\n                     0.117, 0.142, 0.342, 0.285, 0.184, 0.137, 0.162))\n\n\n# this is it:\nggplot(metrics, aes(x = model, y = adj._r_squared, fill = trait)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Adjusted R squared by Trait and Model\",\n       x = \"Model\",\n       y = \"Adjusted R-squared\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_brewer(palette = \"Set2\")","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:58.344628Z","iopub.execute_input":"2023-09-18T09:41:58.347278Z","iopub.status.idle":"2023-09-18T09:41:59.077027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Making predictions on the test set","metadata":{}},{"cell_type":"markdown","source":"For the competition we have to make **predictions** for the data in the **test set**\n\n- The predictions will be evaluated by computing the **Root Means Square Error**:\n    - $\\displaystyle{RMSE =\\sqrt{{1 \\over 5n} \\sum_{k \\in \\{cEXT, \\ldots, cOPN\\}} \\sum_{i=1}^n (y_{ik} - \\hat y_{ik})^2}}$\n    - Here \n        - $y_{ik}$ is the observed value for vlogger $i$ \n        - $\\hat y_{ik}$ is your prediction for vlogger $i$\n        \n        \nYou will have to take the following steps:\n\n1. Extract the test set from the `vlogger_df`\n2. Compute predictions for the test set using your model\n3. Write those predictions to file in the right format\n\nThe following gives code for these steps in order.","metadata":{}},{"cell_type":"markdown","source":"### 6.1 The test set\n\nThe test set are those `vlogId` that are missing in the personality scores data frame `pers`. They are the rows in `vlogger_df` for which the personality scores are missing:","metadata":{}},{"cell_type":"code","source":"testset_vloggers <- vlogger_df_full_both %>% \n    filter(is.na(Extr))\n\nhead(testset_vloggers)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:59.080204Z","iopub.execute_input":"2023-09-18T09:41:59.081786Z","iopub.status.idle":"2023-09-18T09:41:59.139064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.2 Predictions\n\nContinuing the example `fit_mlm` model above, for almost all models we will encounter use the `predict()` function.\n\n- `predict()` function exists for most model fit function like `lm`, `glm`, etc., that we encounter\n    - first argument should be a model object (`fit_mlm` in the example)\n    - second argument should be a data frame with the test set\n    - optionnaly, a third argument specifies type of response:\n      - for `lm` object only `type = \"resp\"`\n      - for `glm` object `type = \"pred\"` (linear predictor) or `type = \"resp\"` ('response' &rarr; probabilities)\n\nFor example:","metadata":{}},{"cell_type":"code","source":"pred_mlm <- predict(model_stepped, new = testset_vloggers)\n\n# Always check the output\nhead(pred_mlm)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:59.141751Z","iopub.execute_input":"2023-09-18T09:41:59.143224Z","iopub.status.idle":"2023-09-18T09:41:59.174945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compute output data frame\ntestset_pred <- testset_vloggers %>% \n    mutate(\n        Extr = pred_mlm[,'Extr'], \n        Agr  = pred_mlm[,'Agr' ],\n        Cons = pred_mlm[,'Cons'],\n        Emot = pred_mlm[,'Emot'],\n        Open = pred_mlm[,'Open']\n    ) %>%\n    dplyr::select(vlogId, Extr:Open)\n\nhead(testset_pred)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:59.178906Z","iopub.execute_input":"2023-09-18T09:41:59.180547Z","iopub.status.idle":"2023-09-18T09:41:59.232902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.3 Writing predictions to file\n\nYou need to upload your predictions in .csv file. However, there are multiple columns: `Extr`, `Agr`, `Cons`, `Emot`, `Open`, while Kaggle expects **long format**!\n\nWhat does long format look like?\n\n- Every prediction on a single line.\n- Columns `vlogId` and `pers_axis` to map prediction *vlogger ID* and *personality axis*.\n\nTo achieve this, `pivot_longer` to store the personality profile values into a single `value` column:","metadata":{}},{"cell_type":"code","source":"testset_pred_long <- testset_pred %>% \n    pivot_longer(c(Extr, Agr, Cons, Emot, Open), names_to = \"pers_axis\")\n\nhead(testset_pred_long)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:59.235511Z","iopub.execute_input":"2023-09-18T09:41:59.236933Z","iopub.status.idle":"2023-09-18T09:41:59.273058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to the competition's [Evaluation instructions](https://www.kaggle.com/competitions/bda-2023-bigfive/overview/evaluation), Kaggle expects file with two colums: `Id` and `Expected`.\n  \nThe [Evaluation instructions](https://www.kaggle.com/competitions/bda-2023-bigfive/overview/evaluation) specifies we need to encode the `Agr` prediction for `VLOG8` as `VLOG8_Agr` in the `Id` column. To achieve this use `unite()` function of `dplyr`.\n\n`unite()` take:\n\n- a data frame as its first argument (implicitely passed by the piping operator `%>%`)\n- the name of new column as its second argument (`Id` below)\n- all extra arguments (`vlogId` and `pers_axis` below) are concatenated with an underscore in between\n\nThen write the resulting data frame to a .csv file.","metadata":{}},{"cell_type":"code","source":"# Obtain the right format for Kaggle\ntestset_pred_final <- testset_pred_long %>%\n    unite(Id, vlogId, pers_axis) %>%\n    rename(Expected = value)\n\n# Check if we succeeded\nhead(testset_pred_final)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:59.275657Z","iopub.execute_input":"2023-09-18T09:41:59.277059Z","iopub.status.idle":"2023-09-18T09:41:59.313292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Write to csv\nwrite_csv(testset_pred_final, file = \"predictions.csv\")\n\n# Check if the file was written successfully.\ndir()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:59.315862Z","iopub.execute_input":"2023-09-18T09:41:59.317278Z","iopub.status.idle":"2023-09-18T09:41:59.35447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Conclusion","metadata":{}},{"cell_type":"markdown","source":"This notebooks shows our progress to try and find the best model for the youtube personality dataset. By adding audiovisual features, different sentiment categories, and stepwise regression ended up with significantly higher adjusted R-squared compared to the first 'simple' model that we tried, thus explaining more of the variance in the data. This strategy got us in the top 5 on the leaderboard for the first round. In the end, we weren't able to properly use the average RMSE due to the lack of the test data set.","metadata":{}},{"cell_type":"markdown","source":"## 8. RMSE Part that we left out","metadata":{}},{"cell_type":"markdown","source":"In order to compare the different models, we used the adjusted R squared on the one hand for assessing the goodness of model fit and the RMSE on the other as a measure of prediction accuracy. \nWe have decided on the adjusted R squared instead of the 'normal' R squared, because besides measuring the overall fit, it also punishes for the amount of predictors in the model. One main benefit of the RMSE is that it is on the same scale as the predicted Big Five traits, which facilitates understanding model performance. It indicates the error terms of the Big Five ratings by looking at the differences between the predictions for the vloggers and the actual values of the vloggers.","metadata":{}},{"cell_type":"code","source":"# remove NA from vlogger_df to get the actual values without the test vloggers\ntrainset_vloggers <- vlogger_df %>% \n    filter(!is.na(Extr)) \n\noutput <- numeric()\nX <- c(trainset_vloggers$Extr, trainset_vloggers$Agr, \n    trainset_vloggers$Cons, trainset_vloggers$Emot,\n    trainset_vloggers$Open)\n\n# defining RMSE function from given formula, where x is actual data, y predicted\nrmse <- function(x, y) { \n  sqrt(((mean((x - y)^2)) * (mean(x))) / (5 * length(x)))}\n\n# looping through each average Big Five trait and compare it to its model prediction\nfor(i in 1:length(X)) { \n    output[i]<- ModelMetrics::rmse(X[i], predict(model1))\n}\nmean(output)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:41:59.357106Z","iopub.execute_input":"2023-09-18T09:41:59.358555Z","iopub.status.idle":"2023-09-18T09:41:59.544464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**References**\n\nKern, M. L., Eichstaedt, J. C., Schwartz, H. A., Dziurzynski, L., Ungar, L. H., Stillwell, D. J., ... & Seligman, M. E. (2014). The online social self: An open vocabulary approach to personality. *Assessment*, *21*(2), 158-169.","metadata":{}}]}
{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jules3110/bda-competition-1-group-15-round-2?scriptVersionId=149740349\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Competition 1: Personality Profiling of YouTube vloggers (round 2 ) #\n\n*Team 15: Lisa, Bart, & Julius*\n\n\nThis notebook tests different models that predict vloggers personality (Big Five) based on their video transcripts, audiovisual features, and gender. The Big Five personality traits are openness to experience, conscientiousness, extroversion, agreeableness, and emotional stability. We proceed in several steps:\n\n1. Import and format the input data\n2. Extract relevant features from the transcripts\n3. Formulate and compare different models\n4. Select the best model\n5. Predict unknown personality scores ","metadata":{}},{"cell_type":"markdown","source":"Before we start, we load the tidyverse and tidytext packages necessary to run our code.","metadata":{}},{"cell_type":"code","source":"library(tidyverse) \nlibrary(tidytext)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T07:54:00.84744Z","iopub.execute_input":"2023-09-18T07:54:00.848955Z","iopub.status.idle":"2023-09-18T07:54:00.862379Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## 1. Import and format input data ##\n\n\nFirst, we identifiy the file paths of our transcripts, audiovisual, gender, and personality data.","metadata":{}},{"cell_type":"code","source":"youtube_dir <- file.path(list.files(\"../input\", full.names = TRUE), \"youtube-personality\") # file path to Youtube Personality directory\ndirectory_content <- list.files(youtube_dir, full.names = TRUE) # contents of Youtube Personality directory\nprint(directory_content)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T07:54:00.864984Z","iopub.execute_input":"2023-09-18T07:54:00.866425Z","iopub.status.idle":"2023-09-18T07:54:00.891705Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"[1] \"../input/youtube-personality/youtube-personality/README.txt\"                                                 \n[2] \"../input/youtube-personality/youtube-personality/transcripts\"                                                \n[3] \"../input/youtube-personality/youtube-personality/YouTube-Personality-audiovisual_features.csv\"               \n[4] \"../input/youtube-personality/youtube-personality/YouTube-Personality-gender.csv\"                             \n[5] \"../input/youtube-personality/youtube-personality/YouTube-Personality-Personality_impression_scores_train.csv\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"For each file, we save the corresponding file path.","metadata":{}},{"cell_type":"code","source":"path_to_transcripts <- directory_content[2] # path to directory with transcript\nAudioVisual_file    <- directory_content[3] # path to .csv file with audiovisual data\nGender_file         <- directory_content[4] # path to .csv file with gender data\nPersonality_file    <- directory_content[5] # path to .csv file with personality data","metadata":{"execution":{"iopub.status.busy":"2023-09-18T07:54:00.89383Z","iopub.execute_input":"2023-09-18T07:54:00.894915Z","iopub.status.idle":"2023-09-18T07:54:00.908628Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"While the audiovisual, gender, and personality data are stored in files containing data for all vloggers (except missing values), the transcripts are stored individually for each vlogger in the transcripts directory.","metadata":{}},{"cell_type":"code","source":"transcript_files <- list.files(path_to_transcripts, full.names = TRUE) # contents of transcripts directory\nprint(head(transcript_files))","metadata":{"execution":{"iopub.status.busy":"2023-09-18T07:54:00.910745Z","iopub.execute_input":"2023-09-18T07:54:00.911819Z","iopub.status.idle":"2023-09-18T07:54:00.929086Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"[1] \"../input/youtube-personality/youtube-personality/transcripts/VLOG1.txt\"  \n[2] \"../input/youtube-personality/youtube-personality/transcripts/VLOG10.txt\" \n[3] \"../input/youtube-personality/youtube-personality/transcripts/VLOG100.txt\"\n[4] \"../input/youtube-personality/youtube-personality/transcripts/VLOG102.txt\"\n[5] \"../input/youtube-personality/youtube-personality/transcripts/VLOG103.txt\"\n[6] \"../input/youtube-personality/youtube-personality/transcripts/VLOG104.txt\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The file name for each vlogger's transcript contains the vlogger ID, which we extract to later use as identifiers in our data frames.","metadata":{}},{"cell_type":"code","source":"vlogId <- basename(transcript_files) # extracting file names\nvlogId <-str_replace(vlogId, pattern = \".txt$\", replacement = \"\") # remove .txt\nhead(vlogId)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T07:54:00.931134Z","iopub.execute_input":"2023-09-18T07:54:00.932256Z","iopub.status.idle":"2023-09-18T07:54:00.949591Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/html":"<style>\n.list-inline {list-style: none; margin:0; padding: 0}\n.list-inline>li {display: inline-block}\n.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n</style>\n<ol class=list-inline><li>'VLOG1'</li><li>'VLOG10'</li><li>'VLOG100'</li><li>'VLOG102'</li><li>'VLOG103'</li><li>'VLOG104'</li></ol>\n","text/markdown":"1. 'VLOG1'\n2. 'VLOG10'\n3. 'VLOG100'\n4. 'VLOG102'\n5. 'VLOG103'\n6. 'VLOG104'\n\n\n","text/latex":"\\begin{enumerate*}\n\\item 'VLOG1'\n\\item 'VLOG10'\n\\item 'VLOG100'\n\\item 'VLOG102'\n\\item 'VLOG103'\n\\item 'VLOG104'\n\\end{enumerate*}\n","text/plain":"[1] \"VLOG1\"   \"VLOG10\"  \"VLOG100\" \"VLOG102\" \"VLOG103\" \"VLOG104\""},"metadata":{}}]},{"cell_type":"markdown","source":"Next, we combine all transcripts in a data frame with three columns, The first column contains the vlogger IDs, the second column contains the text of the corresponding transcripts, and the third column contains the file names.","metadata":{}},{"cell_type":"code","source":"transcripts_df <- tibble(\n    vlogId = vlogId, # vlogger IDs\n    TEXT = map_chr(transcript_files, ~ paste(readLines(.x), collapse = \"\\\\n\")), # transcripts as string\n    filename = transcript_files # name of source file\n)\nhead(transcripts_df, 2)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T07:54:00.951601Z","iopub.execute_input":"2023-09-18T07:54:00.952693Z","iopub.status.idle":"2023-09-18T07:54:02.205419Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"Warning message in readLines(.x):\n“incomplete final line found on '../input/youtube-personality/youtube-personality/transcripts/VLOG11.txt'”\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<table class=\"dataframe\">\n<caption>A tibble: 2 × 3</caption>\n<thead>\n\t<tr><th scope=col>vlogId</th><th scope=col>TEXT</th><th scope=col>filename</th></tr>\n\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n</thead>\n<tbody>\n\t<tr><td>VLOG1 </td><td>You know what I see - - no, more like hear a lot these days, is people calling other people gay as an insult. Now what makes people come up with calling others gay? Now here's an example. Hey, hey, you wanna trade Pokemon or Ziegfield cards? Or, or, or we can play, we can play superheroes. Oh, can I be Optimus Prime? Dude, you are so gay. Dude, the cool kids do crack. Oh, my mommy says, say no to drugs. Okay, how the hell does playing Pokemon cards or -- or --- or dancing or holding hands with another guy make me homosexual? I don't get these people. \\nThis is how it is in my school. Okay, here's an example. All right, um, when they see two guys are gay, they're together, they're like no, ew, no. No, no that -- that doesn't go together - - you know, two guys, no. two sticks, no. It just doesn't work like . But when they see two girls, they're like, get it on. And I don't get these people. I've never seen someone say like, oh, you're so homosexual or you're so lesbian or you're such a child molester. It is always the word gay, cause apparently gay is now an insult, even though the word means like happy and lively and that kinda giddy feeling you have inside, like -- -- but no you have to turn that happy word into a mean word. Apparently, we can do that now, turning good things into bad things. It's like how Spiderman felt good, but then that -- that -- that grease that gets all over him and then and then evil Dr. Octopus. That's so gay, you like Spiderman. Lar, I'm going to the movies with the guys to watch Mama Mia. \\nYou never know if other people are offended by what you say. I'm not saying you're a bad person if you do it. I used to do it all the time. I'm more focused on why we say it. In the end, we're all the same. You know, there's nothing wrong with it. I was just wondering where it all came from, you know. All right, thanks a lot for watching. Oh, yeah and the club channel is up and running. So, make sure to check that out because there's gonna be a lot of cool stuff on there. We'll do up to like four challenges at a time. We'll do contests, dares, questions. In the end, there's gonna be a lot of viewer interactions, so it's gonna be really fun. We may even put other people on the video too. So check it.                                                                                                                                                                                                                                                                                                                         </td><td>../input/youtube-personality/youtube-personality/transcripts/VLOG1.txt </td></tr>\n\t<tr><td>VLOG10</td><td>Hey everybody, it's Monday, July twenty seventh, two thousand and nine and that means it's time for another edition of XXXX. \\nGovernor Palin's back in the news this week as she transitions from Alaska governor to Alaskan citizen. Pending all power to Lieutenant Governor Parnell, she had a few choice words for the Media. \\nIt is, as throughout all Alaska, that big wild, good wife teaming along the road that is north to the future. That's what we get to see every day. Now what the rest of America gets to see along with us, is in this last frontier there is hope and opportunity and there is country pride. And it is our man and women in uniform securing it. And we are facing tough challenges in America with some seeming to just be hell bent maybe on tearing down our nation, perpetuating some pessimism and suggesting American apologetics. \\nWhat? \\nAnd we can resist enslavement to big central government that pressures hope and opportunity. Be wary of accepting government largesse. It doesn't come free and often accepting it takes away everything that is free. Melting into Washington's powerful, caretaking arms will just suck incentive to work hard and charge our own course right out of us. \\nUh, wait. Is that -- no way, what? She made a good point there at the end. But sometimes I have to wonder if I'm listening to Sarah Palin or Nicholas Fain . \\nIn other news over the weekend I heard the story of Troy Anthony Davis. Do you know who he is? You should. \\nMister Davis was sentenced to death for the murder of an off duty Savannah, Georgia police officer named Mark McPhail back in nineteen ninety one. Davis was convicted solely on the testimony of nine eye witnesses. Since that time three eye witnesses have recanted, admitting that they were coerced and two other eye witnesses admitted that they never even saw the murder take place. \\nDespite a wealth of information that has been presented to the court and some new evidence yet to be presented, Mister Davis remains on death row after eighteen years. For more information about Troy Anthony Davis and how you can help in his case, check out IAMTROY dot com. \\nThat's all I've got for this week for everybody. I hope you enjoyed the show because although I started recording on Monday, July twenty seventh, it's Tuesday, July twenty eighth and that time has come. Gotta get out of here for work, new work schedule, so until next time, keep checking out XXXX dot com for daily blog posts, updates and etcetera and meet me back here Monday for new video or XXXX. Thanks for watching. </td><td>../input/youtube-personality/youtube-personality/transcripts/VLOG10.txt</td></tr>\n</tbody>\n</table>\n","text/markdown":"\nA tibble: 2 × 3\n\n| vlogId &lt;chr&gt; | TEXT &lt;chr&gt; | filename &lt;chr&gt; |\n|---|---|---|\n| VLOG1  | You know what I see - - no, more like hear a lot these days, is people calling other people gay as an insult. Now what makes people come up with calling others gay? Now here's an example. Hey, hey, you wanna trade Pokemon or Ziegfield cards? Or, or, or we can play, we can play superheroes. Oh, can I be Optimus Prime? Dude, you are so gay. Dude, the cool kids do crack. Oh, my mommy says, say no to drugs. Okay, how the hell does playing Pokemon cards or -- or --- or dancing or holding hands with another guy make me homosexual? I don't get these people. \\nThis is how it is in my school. Okay, here's an example. All right, um, when they see two guys are gay, they're together, they're like no, ew, no. No, no that -- that doesn't go together - - you know, two guys, no. two sticks, no. It just doesn't work like . But when they see two girls, they're like, get it on. And I don't get these people. I've never seen someone say like, oh, you're so homosexual or you're so lesbian or you're such a child molester. It is always the word gay, cause apparently gay is now an insult, even though the word means like happy and lively and that kinda giddy feeling you have inside, like -- -- but no you have to turn that happy word into a mean word. Apparently, we can do that now, turning good things into bad things. It's like how Spiderman felt good, but then that -- that -- that grease that gets all over him and then and then evil Dr. Octopus. That's so gay, you like Spiderman. Lar, I'm going to the movies with the guys to watch Mama Mia. \\nYou never know if other people are offended by what you say. I'm not saying you're a bad person if you do it. I used to do it all the time. I'm more focused on why we say it. In the end, we're all the same. You know, there's nothing wrong with it. I was just wondering where it all came from, you know. All right, thanks a lot for watching. Oh, yeah and the club channel is up and running. So, make sure to check that out because there's gonna be a lot of cool stuff on there. We'll do up to like four challenges at a time. We'll do contests, dares, questions. In the end, there's gonna be a lot of viewer interactions, so it's gonna be really fun. We may even put other people on the video too. So check it.                                                                                                                                                                                                                                                                                                                          | ../input/youtube-personality/youtube-personality/transcripts/VLOG1.txt  |\n| VLOG10 | Hey everybody, it's Monday, July twenty seventh, two thousand and nine and that means it's time for another edition of XXXX. \\nGovernor Palin's back in the news this week as she transitions from Alaska governor to Alaskan citizen. Pending all power to Lieutenant Governor Parnell, she had a few choice words for the Media. \\nIt is, as throughout all Alaska, that big wild, good wife teaming along the road that is north to the future. That's what we get to see every day. Now what the rest of America gets to see along with us, is in this last frontier there is hope and opportunity and there is country pride. And it is our man and women in uniform securing it. And we are facing tough challenges in America with some seeming to just be hell bent maybe on tearing down our nation, perpetuating some pessimism and suggesting American apologetics. \\nWhat? \\nAnd we can resist enslavement to big central government that pressures hope and opportunity. Be wary of accepting government largesse. It doesn't come free and often accepting it takes away everything that is free. Melting into Washington's powerful, caretaking arms will just suck incentive to work hard and charge our own course right out of us. \\nUh, wait. Is that -- no way, what? She made a good point there at the end. But sometimes I have to wonder if I'm listening to Sarah Palin or Nicholas Fain . \\nIn other news over the weekend I heard the story of Troy Anthony Davis. Do you know who he is? You should. \\nMister Davis was sentenced to death for the murder of an off duty Savannah, Georgia police officer named Mark McPhail back in nineteen ninety one. Davis was convicted solely on the testimony of nine eye witnesses. Since that time three eye witnesses have recanted, admitting that they were coerced and two other eye witnesses admitted that they never even saw the murder take place. \\nDespite a wealth of information that has been presented to the court and some new evidence yet to be presented, Mister Davis remains on death row after eighteen years. For more information about Troy Anthony Davis and how you can help in his case, check out IAMTROY dot com. \\nThat's all I've got for this week for everybody. I hope you enjoyed the show because although I started recording on Monday, July twenty seventh, it's Tuesday, July twenty eighth and that time has come. Gotta get out of here for work, new work schedule, so until next time, keep checking out XXXX dot com for daily blog posts, updates and etcetera and meet me back here Monday for new video or XXXX. Thanks for watching.  | ../input/youtube-personality/youtube-personality/transcripts/VLOG10.txt |\n\n","text/latex":"A tibble: 2 × 3\n\\begin{tabular}{lll}\n vlogId & TEXT & filename\\\\\n <chr> & <chr> & <chr>\\\\\n\\hline\n\t VLOG1  & You know what I see - - no, more like hear a lot these days, is people calling other people gay as an insult. Now what makes people come up with calling others gay? Now here's an example. Hey, hey, you wanna trade Pokemon or Ziegfield cards? Or, or, or we can play, we can play superheroes. Oh, can I be Optimus Prime? Dude, you are so gay. Dude, the cool kids do crack. Oh, my mommy says, say no to drugs. Okay, how the hell does playing Pokemon cards or -- or --- or dancing or holding hands with another guy make me homosexual? I don't get these people. \\textbackslash{}nThis is how it is in my school. Okay, here's an example. All right, um, when they see two guys are gay, they're together, they're like no, ew, no. No, no that -- that doesn't go together - - you know, two guys, no. two sticks, no. It just doesn't work like . But when they see two girls, they're like, get it on. And I don't get these people. I've never seen someone say like, oh, you're so homosexual or you're so lesbian or you're such a child molester. It is always the word gay, cause apparently gay is now an insult, even though the word means like happy and lively and that kinda giddy feeling you have inside, like -- -- but no you have to turn that happy word into a mean word. Apparently, we can do that now, turning good things into bad things. It's like how Spiderman felt good, but then that -- that -- that grease that gets all over him and then and then evil Dr. Octopus. That's so gay, you like Spiderman. Lar, I'm going to the movies with the guys to watch Mama Mia. \\textbackslash{}nYou never know if other people are offended by what you say. I'm not saying you're a bad person if you do it. I used to do it all the time. I'm more focused on why we say it. In the end, we're all the same. You know, there's nothing wrong with it. I was just wondering where it all came from, you know. All right, thanks a lot for watching. Oh, yeah and the club channel is up and running. So, make sure to check that out because there's gonna be a lot of cool stuff on there. We'll do up to like four challenges at a time. We'll do contests, dares, questions. In the end, there's gonna be a lot of viewer interactions, so it's gonna be really fun. We may even put other people on the video too. So check it.                                                                                                                                                                                                                                                                                                                          & ../input/youtube-personality/youtube-personality/transcripts/VLOG1.txt \\\\\n\t VLOG10 & Hey everybody, it's Monday, July twenty seventh, two thousand and nine and that means it's time for another edition of XXXX. \\textbackslash{}nGovernor Palin's back in the news this week as she transitions from Alaska governor to Alaskan citizen. Pending all power to Lieutenant Governor Parnell, she had a few choice words for the Media. \\textbackslash{}nIt is, as throughout all Alaska, that big wild, good wife teaming along the road that is north to the future. That's what we get to see every day. Now what the rest of America gets to see along with us, is in this last frontier there is hope and opportunity and there is country pride. And it is our man and women in uniform securing it. And we are facing tough challenges in America with some seeming to just be hell bent maybe on tearing down our nation, perpetuating some pessimism and suggesting American apologetics. \\textbackslash{}nWhat? \\textbackslash{}nAnd we can resist enslavement to big central government that pressures hope and opportunity. Be wary of accepting government largesse. It doesn't come free and often accepting it takes away everything that is free. Melting into Washington's powerful, caretaking arms will just suck incentive to work hard and charge our own course right out of us. \\textbackslash{}nUh, wait. Is that -- no way, what? She made a good point there at the end. But sometimes I have to wonder if I'm listening to Sarah Palin or Nicholas Fain . \\textbackslash{}nIn other news over the weekend I heard the story of Troy Anthony Davis. Do you know who he is? You should. \\textbackslash{}nMister Davis was sentenced to death for the murder of an off duty Savannah, Georgia police officer named Mark McPhail back in nineteen ninety one. Davis was convicted solely on the testimony of nine eye witnesses. Since that time three eye witnesses have recanted, admitting that they were coerced and two other eye witnesses admitted that they never even saw the murder take place. \\textbackslash{}nDespite a wealth of information that has been presented to the court and some new evidence yet to be presented, Mister Davis remains on death row after eighteen years. For more information about Troy Anthony Davis and how you can help in his case, check out IAMTROY dot com. \\textbackslash{}nThat's all I've got for this week for everybody. I hope you enjoyed the show because although I started recording on Monday, July twenty seventh, it's Tuesday, July twenty eighth and that time has come. Gotta get out of here for work, new work schedule, so until next time, keep checking out XXXX dot com for daily blog posts, updates and etcetera and meet me back here Monday for new video or XXXX. Thanks for watching.  & ../input/youtube-personality/youtube-personality/transcripts/VLOG10.txt\\\\\n\\end{tabular}\n","text/plain":"  vlogId\n1 VLOG1 \n2 VLOG10\n  TEXT                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n1 You know what I see - - no, more like hear a lot these days, is people calling other people gay as an insult. Now what makes people come up with calling others gay? Now here's an example. Hey, hey, you wanna trade Pokemon or Ziegfield cards? Or, or, or we can play, we can play superheroes. Oh, can I be Optimus Prime? Dude, you are so gay. Dude, the cool kids do crack. Oh, my mommy says, say no to drugs. Okay, how the hell does playing Pokemon cards or -- or --- or dancing or holding hands with another guy make me homosexual? I don't get these people. \\\\nThis is how it is in my school. Okay, here's an example. All right, um, when they see two guys are gay, they're together, they're like no, ew, no. No, no that -- that doesn't go together - - you know, two guys, no. two sticks, no. It just doesn't work like . But when they see two girls, they're like, get it on. And I don't get these people. I've never seen someone say like, oh, you're so homosexual or you're so lesbian or you're such a child molester. It is always the word gay, cause apparently gay is now an insult, even though the word means like happy and lively and that kinda giddy feeling you have inside, like -- -- but no you have to turn that happy word into a mean word. Apparently, we can do that now, turning good things into bad things. It's like how Spiderman felt good, but then that -- that -- that grease that gets all over him and then and then evil Dr. Octopus. That's so gay, you like Spiderman. Lar, I'm going to the movies with the guys to watch Mama Mia. \\\\nYou never know if other people are offended by what you say. I'm not saying you're a bad person if you do it. I used to do it all the time. I'm more focused on why we say it. In the end, we're all the same. You know, there's nothing wrong with it. I was just wondering where it all came from, you know. All right, thanks a lot for watching. Oh, yeah and the club channel is up and running. So, make sure to check that out because there's gonna be a lot of cool stuff on there. We'll do up to like four challenges at a time. We'll do contests, dares, questions. In the end, there's gonna be a lot of viewer interactions, so it's gonna be really fun. We may even put other people on the video too. So check it.                                                                                                                                                                                                                                                                                                                         \n2 Hey everybody, it's Monday, July twenty seventh, two thousand and nine and that means it's time for another edition of XXXX. \\\\nGovernor Palin's back in the news this week as she transitions from Alaska governor to Alaskan citizen. Pending all power to Lieutenant Governor Parnell, she had a few choice words for the Media. \\\\nIt is, as throughout all Alaska, that big wild, good wife teaming along the road that is north to the future. That's what we get to see every day. Now what the rest of America gets to see along with us, is in this last frontier there is hope and opportunity and there is country pride. And it is our man and women in uniform securing it. And we are facing tough challenges in America with some seeming to just be hell bent maybe on tearing down our nation, perpetuating some pessimism and suggesting American apologetics. \\\\nWhat? \\\\nAnd we can resist enslavement to big central government that pressures hope and opportunity. Be wary of accepting government largesse. It doesn't come free and often accepting it takes away everything that is free. Melting into Washington's powerful, caretaking arms will just suck incentive to work hard and charge our own course right out of us. \\\\nUh, wait. Is that -- no way, what? She made a good point there at the end. But sometimes I have to wonder if I'm listening to Sarah Palin or Nicholas Fain . \\\\nIn other news over the weekend I heard the story of Troy Anthony Davis. Do you know who he is? You should. \\\\nMister Davis was sentenced to death for the murder of an off duty Savannah, Georgia police officer named Mark McPhail back in nineteen ninety one. Davis was convicted solely on the testimony of nine eye witnesses. Since that time three eye witnesses have recanted, admitting that they were coerced and two other eye witnesses admitted that they never even saw the murder take place. \\\\nDespite a wealth of information that has been presented to the court and some new evidence yet to be presented, Mister Davis remains on death row after eighteen years. For more information about Troy Anthony Davis and how you can help in his case, check out IAMTROY dot com. \\\\nThat's all I've got for this week for everybody. I hope you enjoyed the show because although I started recording on Monday, July twenty seventh, it's Tuesday, July twenty eighth and that time has come. Gotta get out of here for work, new work schedule, so until next time, keep checking out XXXX dot com for daily blog posts, updates and etcetera and meet me back here Monday for new video or XXXX. Thanks for watching. \n  filename                                                               \n1 ../input/youtube-personality/youtube-personality/transcripts/VLOG1.txt \n2 ../input/youtube-personality/youtube-personality/transcripts/VLOG10.txt"},"metadata":{}}]},{"cell_type":"markdown","source":"The personality, audiovisual, and gender files already contain the vlogger IDs and corresponding data. The column with the vlogger IDs is called 'vlogId' in the personality and audiovisual data but has no name in the gender data, so we need to add it before we can join them into a combined data frame by the vlogger IDs. We use a left-join to make sure that we keep the data of all vloggers for whom we have scores on the outcome variables (i.e. personality traits. This results in one data frame 'vlogger_df' with personality, audiovisual, and gender data for each vlogger.","metadata":{}},{"cell_type":"code","source":"pers_df          <- read_delim(Personality_file, delim=\"\") # import personality scores\naudio_vis_df     <- read.delim(AudioVisual_file, head=TRUE, sep=\"\") # import audiovisual data\ngender_df        <- read.delim(Gender_file, head=FALSE, sep=\"\", skip = 2) # import gender data\nnames(gender_df) <- c(\"vlogId\", \"gender\") # add column names to gender data\n\nvlogger_df       <- list(pers_df, audio_vis_df, gender_df) %>%\n                        reduce(left_join, by=\"vlogId\") # join data by vlogger ID\nhead(vlogger_df)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T07:54:02.207423Z","iopub.execute_input":"2023-09-18T07:54:02.208453Z","iopub.status.idle":"2023-09-18T07:54:02.246643Z"},"trusted":true},"execution_count":36,"outputs":[{"ename":"ERROR","evalue":"Error: `delim` must be at least one character, use `read_table()` for whitespace delimited input.\n","traceback":["Error: `delim` must be at least one character, use `read_table()` for whitespace delimited input.\nTraceback:\n","1. read_delim(Personality_file, delim = \"\")","2. stop(\"`delim` must be at least one character, \", \"use `read_table()` for whitespace delimited input.\", \n .     call. = FALSE)"],"output_type":"error"}]},{"cell_type":"markdown","source":"## 2. Extract relevant features from the transcripts ##","metadata":{}},{"cell_type":"markdown","source":"Before we can scan the transcripts for relevant features, we need to split them into tokens in a new 'transcripts_tokenized' data frame. Tokens can be categorised using different lexicons. We decided to use words as out tokens and as a step of pre-processing the tokenized transcripts we exclude so-called stopwords, which carry little meaning by themselves. We were deciding between the 'SMART' stopword list from the tm package and the 'snowball' list of stopwords from tidytext package, because the later is a bit focused on certain things e.g. exaggerations, which might carry meaning in the word lists. In the end we agreed on using the stopwords from the 'snowball' list, because it consists only of 175 words (vs. 571 words from 'SMART') and therefore remove less words from our tokenized words, which potentially carry meaning and leads to a better prediction model. On top of that, after importing the lexicons in a later step, we also checked for any accidental removal of imporant words by looking at the overlap between stopwords and the ocean words list, with which we were fine. Apart from this we thought about identifying near zero variance of the tokenized transcript as well as checking for highly correlated variables and highly correlated linear combinations, in order to improve the model performance. It turned out this is not really applicable to the tokenized transcripts, which are encoded as characters. To finish off our pre-processing we wanted to have all tokenized words in lowercase to have a coherent representation of words. ","metadata":{}},{"cell_type":"code","source":"# Visualisation of adjusted R squared\n\nexample_metrics = data.frame(\n    model = c(\"model1\", \"model2\"),\n    trait = c(\"Extraversion\",\"Agreeableness\", \"Conscientiousness\", \"Emotional availability\", \"Openness\"),\n    adj._r_squared = c(-0.003, 0.259, 0.098, 00956, 0, 0.093, 0.252, 0.041, 0.079, 0.056))\n\nggplot(example_metrics, aes(x = reorder(factor(model),adj._r_squared), y = adj._r_squared)) +\n    geom_bar(stat = \"identity\", fill = \"steelblue\") +\n    geom_text(aes(label = train_rmse), hjust = -0.1, size = 3) +\n    coord_flip() +\n    labs(\n        x = \"Model\",\n        y = \"Train RMSE\",\n        title = \"Performance Comparison\"\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stopwords <- get_stopwords() # 'snowball' list of stopwords from tidytext package \ntranscripts_tokenized <- transcripts_df %>%\n    unnest_tokens(word, TEXT, token = 'words') %>% # split text into words\n    mutate(word = tolower(word)) %>% # converting words into lowercase\n    anti_join(stopwords, by = 'word') # remove stopwords\nhead(transcripts_tokenized)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Trying out different stopword list called SMART\n# Load SMART stopwords from the tm package\n#install.packages(\"tm\")\nlibrary(tm)\n#install.packages(\"NLP\")\nlibrary(NLP)\n\n# Access SMART stopwords\nstopwords <- stopwords(\"SMART\") # the SMART stopwords are less focused on exaggerations, but still have personal pronounce in there\n# but consists of more words 571 vs. 175 from snowball\nstopwords<-as.data.frame(stopwords, col.names=\"word\")\ncolnames(stopwords) <- c(\"word\")\nhead(stopwords)\n\n# remove stopwords\ntranscripts_tokenized = \n    transcripts_tokenized %>%\n    anti_join(stopwords, by = 'word') \n\n# peek at the result\nhead(transcripts_tokenized)\n\n# count tokens (sort according to number of occurences)\nfrequencies <- transcripts_tokenized %>%\n    count(word, sort=TRUE)\n\n# load NRC word list\nnrc = get_lexicon('nrc')\n\n# Do an left join an essay token data fame and nrc word list\ntranscript_features_df = left_join(transcripts_tokenized, nrc, by = 'word', relationship='many-to-many')\ntranscript_features_df <- transcript_features_df[,-2]\n# Calculate sentiment scores\ntranscript_features_df = \n    transcript_features_df %>%\n    count(`vlogId`, sentiment)\ntranscript_features_df <- transcript_features_df %>% pivot_wider(id_cols = 'vlogId', names_from=sentiment, values_from=n, values_fill = 0)\n\nvlogger_df <- right_join(pers_df, transcript_features_df, by = 'vlogId')\nvlogger_df %>% head(6)\n\n# Only for demonstration purposes:\nfit_SMART <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ ., data = vlogger_df[,-1])\nfit_SMART\nsummary(fit_SMART)\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To interpret the words as part of our models, we categorise them using two alternative lexicons. The NRC lexicon from the tidytext package attaches a sentiment to a large number of words. We load the NRC lexicon using the 'get_lexicon' helper function. The OCEAN Words lexicon attaches a personality trait to different words. The OCEAN Words data was taken from the supplementary materials of Kern et al. (2014), who established the association between these words and the Big Fiver personality traits in their study.\n\nWe create a new data frame with one row per word and vlogger (from the 'transcripts_tokenized' data frame) and the category corresponding to each word according to lexicons using a left-join.","metadata":{}},{"cell_type":"code","source":"test <- read_csv(\"../input/ocean-words/OCEAN_words.csv\")\nnames(test) <- c(0, \"hi\")\nhead(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper function to retrieve different lexicons from the 'textdata' package\nget_lexicon <- function(lexicon_name = names(textdata:::download_functions)) {\n    lexicon_name = match.arg(lexicon_name)\n    textdata:::download_functions[[lexicon_name]]('.')\n    rds_filename = paste0(lexicon_name,'.rds')\n    textdata:::process_functions[[lexicon_name]]('.',rds_filename)\n    readr::read_rds(rds_filename)\n}\n\n# Add category of each word according to NRC (sentiment) and OCEAN Words (personality)\nnrc_df                 <- get_lexicon('nrc')\nocean_df               <- read_csv(\"../input/ocean-words/OCEAN_words.csv\")\nnames(ocean_df)        <- c('highExtraversion', 'lowExtraversion', 'highAgreeableness', 'lowAgreeableness',\n                            'lowConscientiousness', 'highConscientiousness', 'highES', 'lowES', 'highOpenness', 'lowOpenness') # clean column names\nocean_df               <- ocean_df %>% pivot_longer(cols = everything(),\n                                                    names_to = 'trait',\n                                                    values_to = 'word') # pivot to two columns with words and personality traits\noverlap_words1         <- semi_join(stopwords, ocean_df, by = \"word\") # check for an accidental removal of imporant words by the stopword list\noverlap_words2         <- semi_join(stopwords, nrc_df, by = \"word\") \ntranscript_features_df <- list(transcripts_tokenized, nrc_df, ocean_df) %>%\n                            reduce(left_join, by = 'word', relationship='many-to-many') # join data by words\nhead(transcript_features_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We turn our tokens into quantitative pedictors by counting how many words of each sentiment and trait appear in each vlogger's transcript. We pivot the resulting date frames into a wide format and join them into a new data frame 'transcript_features_df'. Because the OCEAN Words lexicon contains low and high categories for each personality trait, we subtract the number of words in the low category from those in the high category of each trait to get a composite score for each trait.","metadata":{}},{"cell_type":"code","source":"# Calculate sentiment scores\nsentiment_features_df <- \n    transcript_features_df %>%\n    count(`vlogId`, sentiment) %>%\n    pivot_wider(id_cols = 'vlogId', names_from=sentiment, values_from=n, values_fill = 0) # pivot to wide format to faciliate join\n\n# Calculate trait scores\ntrait_features_df <- \n    transcript_features_df %>%\n    count(`vlogId`, trait) %>%\n    pivot_wider(id_cols = 'vlogId', names_from=trait, values_from=n, values_fill = 0) # pivot to wide format to faciliate join\n\n\ntranscript_features_df <- left_join(sentiment_features_df, trait_features_df, by = 'vlogId') %>%\n                            mutate(\"Other\" = NA.x + NA.y, .keep = 'unused') %>%\n                            mutate(\"Openness\" = highOpenness - lowOpenness, .keep = 'unused') %>%\n                            mutate(\"Conscientiousness\" = highConscientiousness - lowConscientiousness, .keep = 'unused') %>%\n                            mutate(\"Extraversion\" = highExtraversion - lowExtraversion, .keep = 'unused') %>%\n                            mutate(\"Agreeableness\" = highAgreeableness - lowAgreeableness, .keep = 'unused') %>%\n                            mutate(\"emotionalStability\" = highES - lowES, .keep = 'unused')\nhead(transcript_features_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we merge the new 'transcript_features_df' with the audiovisual, gender, and personality data from the 'vlogger_df'. We now have a data frame with one row per vlogger and their associated personality, audiovisual, gender, and quantified transcript data.","metadata":{}},{"cell_type":"code","source":"vlogger_df <- right_join(vlogger_df, transcript_features_df, by = 'vlogId')\nvlogger_df %>% head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Formulate and compare different models ##","metadata":{}},{"cell_type":"markdown","source":"The following steps include running different multiple linear models, which differ in their degree of flexibility. This ranges from a full linear model with all available predictors to more sparse ones, where we identified the best predictors via a forward, backward and mix selection procedure.","metadata":{}},{"cell_type":"code","source":"fit_mlm <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ ., data = vlogger_df[,-1])\nfit_mlm\nsummary(fit_mlm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In order to compare the different models, we used the adjusted R squared on the one hand for assessing the goodness of model fit and the RMSE on the other as a measure of prediction accuracy. \nWe have decided on the adjusted R squared instead of the 'normal' R squared, because besides measuring the overall fit, it also punishes for the amount of predictors in the model. One main benefit of the RMSE is that it is on the same scale as the predicted Big Five traits, which facilitates understanding model performance. It indicates the error terms of the Big Five ratings by looking at the differences between the predictions for the vloggers and the actual values of the vloggers.","metadata":{}},{"cell_type":"code","source":"trainset_vloggers <- vlogger_df %>% \n    filter(!is.na(Extr)) # remove NA from vlogger_df to get the actual values without the test vloggers\noutput <- numeric()\nX <- c(mean(trainset_vloggers$Extr),mean(trainset_vloggers$Agr), mean(trainset_vloggers$Cons), mean(trainset_vloggers$Emot), mean(trainset_vloggers$Open))\nrmse <- function(x, y) { # defining RMSE function from given formula, where x is actual data, y predicted\n  sqrt(((mean((x - y)^2))*(mean(x)))/(5*length(x)))}\n\nfor(i in 1:length(X)) { # looping through each average Big Five trait and compare it to its model prediction\n    output[i]<- rmse(X[i], predict(fit_mlm))\n}\noutput ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset_vloggers <- vlogger_df %>% \n    filter(!is.na(Extr)) # remove NA from vlogger_df to get the actual values without the test vloggers\noutput <- numeric()\nX <- c(mean(trainset_vloggers$Extr),mean(trainset_vloggers$Agr), mean(trainset_vloggers$Cons), mean(trainset_vloggers$Emot), mean(trainset_vloggers$Open))\nModelMetrics::rmse(predict(model1, mean(trainset_vloggers$Extr))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testset_vloggers = vlogger_df %>% \n   filter(is.na(Extr)) # the test set of vloggers, which have no scores in the Extr, Agr, Cons, Emot, Open","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Select the best model","metadata":{}},{"cell_type":"markdown","source":"## 5. Predict unknown personality scores ##","metadata":{}},{"cell_type":"markdown","source":"**References**\n\nKern, M. L., Eichstaedt, J. C., Schwartz, H. A., Dziurzynski, L., Ungar, L. H., Stillwell, D. J., ... & Seligman, M. E. (2014). The online social self: An open vocabulary approach to personality. *Assessment*, *21*(2), 158-169.","metadata":{}}]}